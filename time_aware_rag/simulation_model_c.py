import os
import sys
import json
import pandas as pd
import random
from openai import OpenAI
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from utils.persona_generator import generate_balanced_personas, Persona
from utils.search_queries import GAMER_TYPE_QUERIES, GENERAL_QUERY
from static_rag.rag_modules import RAGRetriever

# 1. APIí‚¤ ë° í™˜ê²½ ì„¤ì • (LLM Configuration)
# load_dotenv()

# --- LLM ì„¤ì • (Configuration) ---
USE_OLLAMA = False # Local LLM ì‚¬ìš© ì—¬ë¶€
OLLAMA_BASE_URL = "http://localhost:11434/v1"
OLLAMA_MODEL = "qwen3:4b"
OPENAI_MODEL = "gpt-4o-mini"

if USE_OLLAMA:
    print(f"ğŸ”¹ Using Local LLM (Ollama): {OLLAMA_MODEL}")
    client = OpenAI(
        base_url=OLLAMA_BASE_URL,
        api_key="ollama" # OllamaëŠ” api_keyê°€ í•„ìš” ì—†ì§€ë§Œ í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ ë”ë¯¸ ê°’ ì…ë ¥
    )
    MODEL_NAME = OLLAMA_MODEL
else:
    print(f"ğŸ”¸ Using OpenAI API: {OPENAI_MODEL}")
    # api_key = os.getenv("OPENAI_API_KEY")
    # if not api_key:
    #    print("Warning: OPENAI_API_KEY not found in .env")
    #    pass 
    api_key = input("Enter your OpenAI API key: ")
    client = OpenAI(api_key=api_key)
    MODEL_NAME = OPENAI_MODEL
# -------------------------------

OUTPUT_FILE = "time_aware_rag/Team3_TimeAwareRag_Results.csv"
SIMULATION_DATES_FILE = "datasets/simulation_dates.csv"

# =============================================================================
# 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
# =============================================================================

def create_prompt(agent: Persona, current_date: str, context: list):
    context_str = "\n".join(context) if context else "(No reviews found.)"
    
    return f"""[ROLE]
You are a {agent.age} {agent.gender}.
Personality: '{agent.gamer_type_name_display}' ({agent.description})

[DATE]
Today is {current_date}.

[SEARCH RESULTS]
Reviews selected based on your interests and recentness (Time-Weighted):
{context_str}

[TASK]
Decide to buy 'Cyberpunk 2077' or not based strictly on the reviews above.
- The reviews are filtered by relevance and recency.
- Trust these reviews as the most important information available to you.

[OUTPUT]
JSON only:
{{
    "decision": "YES" or "NO",
    "reasoning": "Explain why based on the reviews."
}}
"""

# =============================================================================
# 3. API í˜¸ì¶œ
# =============================================================================

def call_llm(prompt: str) -> dict:
    try:
        res = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "system", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.5
        )
        return json.loads(res.choices[0].message.content)
    except Exception as e:
        print(f"Error: {e}")
        return {"decision": "NO", "reasoning": "Error"}

# =============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ (Main Execution)
# =============================================================================

def run_experiment_b_rag(n_per_type: int = 13):
    print("=" * 70)
    print(f"Task 3: Time Aware Rag Simulation")
    print("=" * 70)

    # RAG ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
    print("Initializing RAG Retriever...")
    retriever = RAGRetriever()

    # ë‚ ì§œ ë¡œë“œ
    dates_df = pd.read_csv(SIMULATION_DATES_FILE)
    simulation_dates = dates_df['date'].tolist()
    
    # ì—ì´ì „íŠ¸ ìƒì„±
    # README: "generate_balanced_personas(n_per_type=13)" (ì´ 104ëª…)
    personas = generate_balanced_personas(n_per_type=n_per_type) 
    print(f"Generated {len(personas)} agents.")

    results = []
    
    # ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„
    total_steps = len(simulation_dates) * len(personas)
    step_count = 0

    for date_str in simulation_dates:
        print(f"\nğŸ“… Date: {date_str}")
        
        for persona in personas:
            step_count += 1
            # 1. ì¿¼ë¦¬ ì„ ì • (Team 3 ë°©ì‹: 4ê°œ ëœë¤ + ì¼ë°˜ ì¿¼ë¦¬)
            agent_queries = GAMER_TYPE_QUERIES.get(persona.gamer_type, [])
            selected_queries = []
            if len(agent_queries) >= 4:
                selected_queries = random.sample(agent_queries, 4)
            else:
                selected_queries = agent_queries # Fallback
            selected_queries.append(GENERAL_QUERY)
            
            # 2. ê²€ìƒ‰ (Team 2 ì •ì  ë¡œì§)
            # ì¿¼ë¦¬ë‹¹ ìƒìœ„ kê°œë¥¼ ê²€ìƒ‰í•˜ê³  í•©ì¹¨
            # Team 3ëŠ” ì¿¼ë¦¬ë‹¹ 100ê°œë¥¼ ê²€ìƒ‰ í›„ ì‹œê°„ ê°ì‡ (Time-Decay) ë­í‚¹ì„ ì ìš©í•˜ì§€ë§Œ,
            # Team 2ëŠ” ìœ ì‚¬ë„(Similarity) ê¸°ë°˜ ìƒìœ„ kê°œë¥¼ ê²€ìƒ‰
            
            candidates = []
            for query in selected_queries:
                # retrieve_reviews í•¨ìˆ˜ëŠ” "- [Date] text..." í˜•ì‹ì„ ë°˜í™˜
                reviews = retriever.retrieve_reviews(query, date_str, top_k=2)
                candidates.extend(reviews)
            
            # ì¤‘ë³µ ì œê±° (ë‹¨ìˆœ ì§‘í•© ì‚¬ìš©)
            unique_candidates = list(set(candidates))
            
            # ìƒìœ„ 5ê°œ ì„ íƒ (Team 3ì™€ ë™ì¼ ê°œìˆ˜)
            final_docs = unique_candidates[:5]
            
            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = create_prompt(persona, date_str, final_docs)
            
            # 4. LLM í˜¸ì¶œ
            print(f"   [{step_count}/{total_steps}] Agent {persona.id}...", end=" ", flush=True)
            res = call_llm(prompt)
            
            decision = res.get("decision", "NO").upper()
            decision = "YES" if "YES" in decision else "NO"
            
            print(f"-> {decision}")
            
            results.append({
                "Agent_ID": persona.id,
                "Name": persona.name,
                "Persona_Type": persona.gamer_type_name_display,
                "Decision": decision,
                "Simulation_Date": date_str,
                "Reasoning": res.get("reasoning", "")
            })

    # ê²°ê³¼ ì €ì¥
    df = pd.DataFrame(results)
    df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
    
    print("\n" + "=" * 70)
    print(f"Simulation completed. Results saved to {OUTPUT_FILE}")
    print("=" * 70)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìœ í˜•ë³„ 1ëª… ìƒì„±)
    run_experiment_b_rag(n_per_type=13)
